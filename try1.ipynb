{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# testing face alignment, as on learnopencv.com\n",
    "# cd Desktop/CMU/\"Face Alignment\"/FaceAverage\n",
    "\n",
    "#Amogh description of this file: used to debug changes in the landmarks and the faces. To be run in Python 2.7 environment. \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying landmark files to calculate the average landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below in raw to avoid copying again"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "copy_main_path='E:/CMU/approach1_april_10/data/CK+/cohn-kanade-images/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print os.listdir(copy_main_path)\n",
    "for subj in os.listdir(copy_main_path):\n",
    "    path2= copy_main_path+subj\n",
    "#     print os.listdir(path2)\n",
    "    for seq in os.listdir(path2):\n",
    "        copy_dest_path='E:/CMU/approach1_april_10/data/CK+/cohn-kanade-images/'+subj+'/'+seq+'/'\n",
    "        copy_landmark_path='E:/CMU/approach1_april_10/data/CK+/Landmarks/'+subj+'/'+seq+'/'\n",
    "        if not os.path.isdir(copy_landmark_path):\n",
    "            continue\n",
    "#         print copy_landmark_path\n",
    "#         print os.listdir(copy_landmark_path)\n",
    "        for file in os.listdir(copy_landmark_path):\n",
    "            src=copy_landmark_path+file\n",
    "            dst=copy_dest_path\n",
    "            shutil.copy(copy_landmark_path+file, copy_dest_path)\n",
    "#             print file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'E:/CMU/approach1_april_10/data/CK+/cohn-kanade-images/' now has landmark files and png files as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining helper functions for aligning images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read points from text files in directory\n",
    "def readPoints(path) :\n",
    "    print 'trying to read points from ', path\n",
    "    # Create an array of array of points.\n",
    "    pointsArray = [];\n",
    "\n",
    "    #List all files in the directory and read points from text files one by one\n",
    "#     for filePath in os.listdir(path):\n",
    "        \n",
    "#         if filePath.endswith(\"Image-20.jpg.txt\"):\n",
    "            \n",
    "            #Create an array of points.\n",
    "    points = [];            \n",
    "            \n",
    "            # Read points from filePath\n",
    "    with open(path) as file :\n",
    "        for line in file :\n",
    "            x, y = line.split()\n",
    "            points.append((int(float(x)), int(float(y))))\n",
    "\n",
    "    # Store array of points\n",
    "    pointsArray.append(points)\n",
    "            \n",
    "    return pointsArray;\n",
    "\n",
    "# Read all jpg images in folder.\n",
    "def readImages(path) :\n",
    "    print 'trying to read points from: ', path\n",
    "    #Create array of array of images.\n",
    "    imagesArray = [];\n",
    "    \n",
    "    #List all files in the directory and read points from text files one by one\n",
    "#     for filePath in os.listdir(path):\n",
    "#         if filePath.endswith(\"Image-20.jpg\"):\n",
    "            # Read image found.\n",
    "    img = cv2.imread(path);\n",
    "\n",
    "    # Convert to floating point\n",
    "    img = np.float32(img)/255.0;\n",
    "\n",
    "    # Add to array of images\n",
    "    imagesArray.append(img);\n",
    "            \n",
    "    return imagesArray;\n",
    "                \n",
    "# Compute similarity transform given two sets of two points.\n",
    "# OpenCV requires 3 pairs of corresponding points.\n",
    "# We are faking the third one.\n",
    "\n",
    "def similarityTransform(inPoints, outPoints) :\n",
    "    s60 = math.sin(60*math.pi/180);\n",
    "    c60 = math.cos(60*math.pi/180);  \n",
    "  \n",
    "    inPts = np.copy(inPoints).tolist();\n",
    "    outPts = np.copy(outPoints).tolist();\n",
    "    \n",
    "    xin = c60*(inPts[0][0] - inPts[1][0]) - s60*(inPts[0][1] - inPts[1][1]) + inPts[1][0];\n",
    "    yin = s60*(inPts[0][0] - inPts[1][0]) + c60*(inPts[0][1] - inPts[1][1]) + inPts[1][1];\n",
    "    \n",
    "    inPts.append([np.int(xin), np.int(yin)]);\n",
    "    \n",
    "    xout = c60*(outPts[0][0] - outPts[1][0]) - s60*(outPts[0][1] - outPts[1][1]) + outPts[1][0];\n",
    "    yout = s60*(outPts[0][0] - outPts[1][0]) + c60*(outPts[0][1] - outPts[1][1]) + outPts[1][1];\n",
    "    \n",
    "    outPts.append([np.int(xout), np.int(yout)]);\n",
    "    \n",
    "    tform = cv2.estimateRigidTransform(np.array([inPts]), np.array([outPts]), False);\n",
    "    \n",
    "    return tform;\n",
    "\n",
    "\n",
    "# Check if a point is inside a rectangle\n",
    "def rectContains(rect, point) :\n",
    "    if point[0] < rect[0] :\n",
    "        return False\n",
    "    elif point[1] < rect[1] :\n",
    "        return False\n",
    "    elif point[0] > rect[2] :\n",
    "        return False\n",
    "    elif point[1] > rect[3] :\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Calculate delanauy triangle\n",
    "def calculateDelaunayTriangles(rect, points):\n",
    "    # Create subdiv\n",
    "    subdiv = cv2.Subdiv2D(rect);\n",
    "   \n",
    "    # Insert points into subdiv\n",
    "    for p in points:\n",
    "            subdiv.insert((p[0], p[1]));\n",
    "\n",
    "   \n",
    "    # List of triangles. Each triangle is a list of 3 points ( 6 numbers )\n",
    "    triangleList = subdiv.getTriangleList();\n",
    "\n",
    "    # Find the indices of triangles in the points array\n",
    "\n",
    "    delaunayTri = []\n",
    "    \n",
    "    for t in triangleList:\n",
    "        pt = []\n",
    "        pt.append((t[0], t[1]))\n",
    "        pt.append((t[2], t[3]))\n",
    "        pt.append((t[4], t[5]))\n",
    "        \n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])        \n",
    "        \n",
    "        if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):\n",
    "            ind = []\n",
    "            for j in xrange(0, 3):\n",
    "                for k in xrange(0, len(points)):                    \n",
    "                    if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):\n",
    "                        ind.append(k)                            \n",
    "            if len(ind) == 3:                                                \n",
    "                delaunayTri.append((ind[0], ind[1], ind[2]))\n",
    "        \n",
    "\n",
    "    \n",
    "    return delaunayTri\n",
    "\n",
    "\n",
    "def constrainPoint(p, w, h) :\n",
    "    p =  ( min( max( p[0], 0 ) , w - 1 ) , min( max( p[1], 0 ) , h - 1 ) )\n",
    "    return p;\n",
    "\n",
    "# Apply affine transform calculated using srcTri and dstTri to src and\n",
    "# output an image of size.\n",
    "def applyAffineTransform(src, srcTri, dstTri, size) :\n",
    "    \n",
    "    # Given a pair of triangles, find the affine transform.\n",
    "    warpMat = cv2.getAffineTransform( np.float32(srcTri), np.float32(dstTri) )\n",
    "    \n",
    "    # Apply the Affine Transform just found to the src image\n",
    "    dst = cv2.warpAffine( src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
    "def warpTriangle(img1, img2, t1, t2) :\n",
    "\n",
    "    # Find bounding rectangle for each triangle\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "\n",
    "    # Offset points by left top corner of the respective rectangles\n",
    "    t1Rect = [] \n",
    "    t2Rect = []\n",
    "    t2RectInt = []\n",
    "\n",
    "    for i in xrange(0, 3):\n",
    "        t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))\n",
    "        t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "        t2RectInt.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "\n",
    "\n",
    "    # Get mask by filling triangle\n",
    "    mask = np.zeros((r2[3], r2[2], 3), dtype = np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0);\n",
    "\n",
    "    # Apply warpImage to small rectangular patches\n",
    "    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "    \n",
    "    size = (r2[2], r2[3])\n",
    "\n",
    "    img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)\n",
    "    \n",
    "    img2Rect = img2Rect * mask\n",
    "\n",
    "    # Copy triangular region of the rectangular patch to the output image\n",
    "    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ( (1.0, 1.0, 1.0) - mask )\n",
    "     \n",
    "    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to alignmage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/AMOGH GUPTA/Desktop/CMU/Face Alignment/FaceAverage/try_faces/'\n",
    "# files_image=\n",
    "# to run the function, enter the absolute path of the image \n",
    "def alignAndcrop(img_abs_path):\n",
    "    # Dimensions of output image\n",
    "    w = 112;\n",
    "    h = 112;\n",
    "    landmark_path=img_abs_path.split('.')[0]+'_landmarks.txt'\n",
    "    # Read points for all images\n",
    "    allPoints = readPoints(landmark_path);\n",
    "    \n",
    "    # Read all images\n",
    "    images = readImages(img_abs_path);\n",
    "    \n",
    "    # Eye corners\n",
    "    eyecornerDst = [ (np.int(0.3 * w ), np.int(h / 3)), (np.int(0.7 * w ), np.int(h / 3)) ];\n",
    "    \n",
    "    imagesNorm = [];\n",
    "    pointsNorm = [];\n",
    "    \n",
    "    # Add boundary points for delaunay triangulation\n",
    "    boundaryPts = np.array([(0,0), (w/2,0), (w-1,0), (w-1,h/2), ( w-1, h-1 ), ( w/2, h-1 ), (0, h-1), (0,h/2) ]);\n",
    "    \n",
    "    # Initialize location of average points to 0s\n",
    "    pointsAvg = np.array([(0,0)]* ( len(allPoints[0]) + len(boundaryPts) ), np.float32());\n",
    "    \n",
    "    n = len(allPoints[0]);\n",
    "\n",
    "    numImages = len(images)\n",
    "    \n",
    "    # Warp images and trasnform landmarks to output coordinate system,\n",
    "    # and find average of transformed landmarks.\n",
    "    \n",
    "    for i in xrange(0, numImages):\n",
    "\n",
    "        points1 = allPoints[i];\n",
    "\n",
    "        # Corners of the eye in input image\n",
    "        eyecornerSrc  = [ allPoints[i][36], allPoints[i][45] ] ;\n",
    "        \n",
    "        # Compute similarity transform\n",
    "        tform = similarityTransform(eyecornerSrc, eyecornerDst);\n",
    "        \n",
    "        # Apply similarity transformation\n",
    "        img = cv2.warpAffine(images[i], tform, (w,h));\n",
    "\n",
    "        # Apply similarity transform on points\n",
    "        points2 = np.reshape(np.array(points1), (68,1,2));        \n",
    "        points = cv2.transform(points2, tform);\n",
    "        points = np.float32(np.reshape(points, (68, 2)));\n",
    "        \n",
    "        # Append boundary points. Will be used in Delaunay Triangulation\n",
    "        points = np.append(points, boundaryPts, axis=0)\n",
    "        \n",
    "        # Calculate location of average landmark points.\n",
    "        pointsAvg = pointsAvg + points / numImages;\n",
    "        \n",
    "        pointsNorm.append(points);\n",
    "        imagesNorm.append(img);\n",
    "        # cv2.imshow('image1', img);\n",
    "#amogh debug - trying to save the average landmarks. pc format is the one like learnopencv tutorial, and the android format is the one with  commas to be able tp save in an array.\n",
    "    # np.savetxt('txt_landmarks/androidformat.txt', pointsAvg,fmt= '%1.3f', newline=',',delimiter=',')\n",
    "    # np.savetxt('txt_landmarks/pcformat.txt', pointsAvg,fmt= '%1.3f',delimiter=' ')\n",
    "    # print pointsAvg\n",
    "\n",
    "    #redefining average points\n",
    "    pointsAvg = [];            \n",
    "    with open('C:/Users/AMOGH GUPTA/Desktop/CMU/Face Alignment/FaceAverage/txt_landmarks/pcformat.txt') as file :\n",
    "        for line in file :\n",
    "            x, y = line.split()\n",
    "            pointsAvg.append([float(x), float(y)])\n",
    "    # print pointsAvg\n",
    "    \n",
    "    rect = (0, 0, w, h);\n",
    "    dt = calculateDelaunayTriangles(rect, np.array(pointsAvg));\n",
    "\n",
    "    # Output image\n",
    "    output = np.zeros((h,w,3), np.float32());\n",
    "\n",
    "    # Warp input images to average image landmarks\n",
    "    for i in xrange(0, len(imagesNorm)) :\n",
    "        img = np.zeros((h,w,3), np.float32());\n",
    "        # Transform triangles one by one\n",
    "        for j in xrange(0, len(dt)) :\n",
    "            tin = []; \n",
    "            tout = [];\n",
    "            \n",
    "            for k in xrange(0, 3) :                \n",
    "                pIn = pointsNorm[i][dt[j][k]];\n",
    "                pIn = constrainPoint(pIn, w, h);\n",
    "                \n",
    "                pOut = pointsAvg[dt[j][k]];\n",
    "                pOut = constrainPoint(pOut, w, h);\n",
    "                \n",
    "                tin.append(pIn);\n",
    "                tout.append(pOut);\n",
    "            \n",
    "            \n",
    "            warpTriangle(imagesNorm[i], img, tin, tout);\n",
    "\n",
    "        cv2.imshow('image3', img);\n",
    "\n",
    "        # Add image intensities for averaging\n",
    "        output = output + img;\n",
    "    # Divide by numImages to get average\n",
    "    output = output / numImages;\n",
    "    mask = np.zeros((output.shape[0], output.shape[1], 3), dtype = np.float32)\n",
    "    # print len(points)\n",
    "    print np.flip(points[2:7],axis=0)\n",
    "    # print(np.concatenate((points[0:4],points[5:8:-1]),axis=0))\n",
    "    landmarks_to_mask=np.concatenate((points[0:17],np.flip(points[17:27],axis=0)),axis=0)\n",
    "    cv2.fillConvexPoly(mask, np.int32(landmarks_to_mask), (1.0, 1.0, 1.0), 16, 0);\n",
    "    output=output*mask\n",
    "    # hog.compute(src,descriptors);\n",
    "    # cv2.circle(output,(10,10),2,(0,0,255),2)\n",
    "    # for p in pointsAvg:\n",
    "        # int p1=(int)p[0]\n",
    "        # int p2=(int)p[1]\n",
    "        # cv2.circle(output, (int(p[0]),int(p[1])), 1, (0,0,255), 1)\n",
    "    for p in points[:27]:\n",
    "        cv2.circle(output, (int(p[0]),int(p[1])), 1, (0,255,0), 1)\n",
    "    # Display result\n",
    "    cv2.imwrite(('E:/CMU/approach1_april_10/data/cropped/'+img_abs_path.split('/')[-1]),output)\n",
    "    cv2.imshow('image', output);\n",
    "    cv2.waitKey(4000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Plan\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CK+ dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First modified the CK+ dataset by using a a script from https://github.com/ifp-uiuc/do-neural-networks-learn-faus-iccvw-2015/tree/master/data_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading FAUs according to file name in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_modified_image_path='E:/CMU/approach1_april_10/data/cohn-kanade-images/'\n",
    "ck_modified_fau_label_path='E:/CMU/approach1_april_10/data/FACS/'\n",
    "ck_original_path='E:/CMU/approach1_april_10/data/CK+/cohn-kanade-images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make a dictionary of the dataset {subj/seq : fau_dictionary}\n",
    "###### This cell populates dict_file_fau in such a way -> {'S129/006': {17.0: 2.0, 23.0: 4.0, 6.0: 2.0, 7.0: 4.0}, 'S129/007': {1.0: 2.0, 2.0: ....}\n",
    "###### also populates dict_subjects_sequence with{'S005': ['001'], 'S010': ['001', '002', '003', '004', '005', '006'], 'S011': ['001', '002', '003', '004', '005', '006'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_file_FAU is populated and has these many elements:  571\n",
      "facs_txt_files_list is populated and has these many elements:  571\n"
     ]
    }
   ],
   "source": [
    "subjects_list=[subj for subj in os.listdir(ck_modified_image_path)]\n",
    "dict_subjects_sequence={}\n",
    "\n",
    "dict_file_FAU={}\n",
    "\n",
    "facs_txt_files_list=[]\n",
    "\n",
    "for subj in subjects_list:\n",
    "#     print \"the subject is: \", subj\n",
    "    dict_subjects_sequence[subj]=[]\n",
    "    sequence_path=ck_modified_fau_label_path+'/'+subj\n",
    "    sequence_list=os.listdir(sequence_path)\n",
    "#     print sequence_list\n",
    "    for seq in sequence_list:\n",
    "        dict_subjects_sequence[subj].append(seq)\n",
    "#         print seq # output eg-  001\n",
    "        file_path=sequence_path+'/'+seq+'/'\n",
    "#         print file_path #output eg- E:/CMU/approach1_april_10/data/FACS//S005/001/\n",
    "        txt_file_path=file_path+os.listdir(file_path)[0]\n",
    "#         print txt_file_path#output eg- E:/CMU/approach1_april_10/data/FACS//S005/001/S005_001_00000011_facs.txt\n",
    "        facs_txt_files_list.append(txt_file_path)\n",
    "        txt_file=open(txt_file_path,'r')\n",
    "        txt=txt_file.readlines()\n",
    "        dict_fau={}\n",
    "        for line in txt:\n",
    "            ln=line.split()\n",
    "            if len(ln)>1:\n",
    "                dict_fau[float(ln[0])]=float(ln[1])\n",
    "        dict_file_FAU[subj+'/'+seq]=dict_fau\n",
    "#         print glob.glob(file_path+'/*.*')[0]\n",
    "print 'dict_file_FAU is populated and has these many elements: ', (len(dict_file_FAU.keys()))\n",
    "print 'facs_txt_files_list is populated and has these many elements: ', len(facs_txt_files_list)\n",
    "# This cell populates dict_file_fau in such a way -> {'S129/006': {17.0: 2.0, 23.0: 4.0, 6.0: 2.0, 7.0: 4.0}, 'S129/007': {1.0: 2.0, 2.0: ....}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:',\n",
       " 'CMU',\n",
       " 'approach1_april_10',\n",
       " 'data',\n",
       " 'FACS',\n",
       " '',\n",
       " 'S005',\n",
       " '001',\n",
       " 'S005_001_00000011_facs.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facs_txt_files_list[0].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This cell populates image_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_file_list has been populated and has these many png files:  327\n"
     ]
    }
   ],
   "source": [
    "image_file_list=[]\n",
    "for subj in os.listdir(ck_modified_image_path):\n",
    "    sequence_path=ck_modified_image_path+'/'+subj\n",
    "    for seq in os.listdir(sequence_path):\n",
    "        seq_im_path=sequence_path+'/'+seq\n",
    "        if (subj in dict_subjects_sequence.keys()) and (seq in dict_subjects_sequence[subj]):\n",
    "            image_file_list.append(os.listdir(seq_im_path)[-1])\n",
    "print 'image_file_list has been populated and has these many png files: ', len(image_file_list)           \n",
    "# this cell populates image_file_list in such a way -> []'S005_001_00000011.png', 'S010_002_00000014.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_abs_file_list has been populated and has these many elements:  327\n"
     ]
    }
   ],
   "source": [
    "image_abs_file_list=[]\n",
    "for f in image_file_list:\n",
    "    part=f.split('_')\n",
    "    image_abs_file_list.append(ck_original_path+part[0]+'/'+part[1]+'/'+f)\n",
    "print 'image_abs_file_list has been populated and has these many elements: ', len(image_abs_file_list)\n",
    "# image_abs_file_list=[[part][0] for f in image_file_list for part in f.split('_')]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for image in image_abs_file_list:\n",
    "#     print image.split('/')[-1]\n",
    "    alignAndcrop(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to read points from  E:/CMU/approach1_april_10/data/CK+/cohn-kanade-images/S005/001/S005_001_00000011_landmarks.txt\n",
      "trying to read points from:  E:/CMU/approach1_april_10/data/CK+/cohn-kanade-images/S005/001/S005_001_00000011.png\n",
      "[[ 38.  86.]\n",
      " [ 31.  81.]\n",
      " [ 25.  74.]\n",
      " [ 22.  66.]\n",
      " [ 18.  57.]]\n"
     ]
    }
   ],
   "source": [
    "alignAndcrop(image_abs_file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debugging function to check in which subj/seq is a particular FAU present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S129/007  has FAU  2.0  value as  2.0\n",
      "S080/005  has FAU  2.0  value as  1.0\n",
      "S506/006  has FAU  2.0  value as  2.0\n",
      "S506/004  has FAU  2.0  value as  4.0\n",
      "S138/007  has FAU  2.0  value as  2.0\n",
      "S090/002  has FAU  2.0  value as  4.0\n",
      "S160/006  has FAU  2.0  value as  2.0\n",
      "S504/004  has FAU  2.0  value as  2.0\n",
      "S504/006  has FAU  2.0  value as  1.0\n",
      "S085/003  has FAU  2.0  value as  3.0\n",
      "S056/003  has FAU  2.0  value as  4.0\n",
      "S999/003  has FAU  2.0  value as  1.0\n",
      "S060/003  has FAU  2.0  value as  4.0\n",
      "S055/006  has FAU  2.0  value as  1.0\n",
      "S051/002  has FAU  2.0  value as  4.0\n",
      "S132/008  has FAU  2.0  value as  3.0\n",
      "S125/007  has FAU  2.0  value as  3.0\n",
      "S126/004  has FAU  2.0  value as  4.0\n",
      "S125/006  has FAU  2.0  value as  3.0\n",
      "S054/003  has FAU  2.0  value as  2.0\n",
      "S068/003  has FAU  2.0  value as  3.0\n",
      "S133/009  has FAU  2.0  value as  1.0\n",
      "This FAU is present in  116\n",
      "It is equal or above threshold in  22\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "j=0\n",
    "for k,v in dict_file_FAU.iteritems():\n",
    "    FAU_id=2.0\n",
    "    FAU_threshold=1.0\n",
    "    if FAU_id in v.keys():\n",
    "            i+=1\n",
    "            if (v[FAU_id]>=FAU_threshold):\n",
    "                j+=1\n",
    "                print k, ' has FAU ', FAU_id ,' value as ', v[FAU_id]           \n",
    "print \"This FAU is present in \", i\n",
    "print \"It is equal or above threshold in \", j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant FAU to tutoring\n",
    "#### 1 inner brow raiser\n",
    "\n",
    "#### 2 outer brow raiser\n",
    "\n",
    "#### 4 brow lowerer\n",
    "\n",
    "#### 5 upper lid raiser\n",
    "\n",
    "#### 7 lid tightener\n",
    "\n",
    "#### 25 lips part\n",
    "\n",
    "#### 26 jaw drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/AMOGH GUPTA/Desktop/CMU/Face Alignment/FaceAverage/try_faces/'\n",
    "    \n",
    "    # Dimensions of output image\n",
    "    w = 112;\n",
    "    h = 112;\n",
    "\n",
    "    # Read points for all images\n",
    "    allPoints = readPoints(path);\n",
    "    \n",
    "    # Read all images\n",
    "    images = readImages(path);\n",
    "    \n",
    "    # Eye corners\n",
    "    eyecornerDst = [ (np.int(0.3 * w ), np.int(h / 3)), (np.int(0.7 * w ), np.int(h / 3)) ];\n",
    "    \n",
    "    imagesNorm = [];\n",
    "    pointsNorm = [];\n",
    "    \n",
    "    # Add boundary points for delaunay triangulation\n",
    "    boundaryPts = np.array([(0,0), (w/2,0), (w-1,0), (w-1,h/2), ( w-1, h-1 ), ( w/2, h-1 ), (0, h-1), (0,h/2) ]);\n",
    "    \n",
    "    # Initialize location of average points to 0s\n",
    "    pointsAvg = np.array([(0,0)]* ( len(allPoints[0]) + len(boundaryPts) ), np.float32());\n",
    "    \n",
    "    n = len(allPoints[0]);\n",
    "\n",
    "    numImages = len(images)\n",
    "    \n",
    "    # Warp images and trasnform landmarks to output coordinate system,\n",
    "    # and find average of transformed landmarks.\n",
    "    \n",
    "    for i in xrange(0, numImages):\n",
    "\n",
    "        points1 = allPoints[i];\n",
    "\n",
    "        # Corners of the eye in input image\n",
    "        eyecornerSrc  = [ allPoints[i][36], allPoints[i][45] ] ;\n",
    "        \n",
    "        # Compute similarity transform\n",
    "        tform = similarityTransform(eyecornerSrc, eyecornerDst);\n",
    "        \n",
    "        # Apply similarity transformation\n",
    "        img = cv2.warpAffine(images[i], tform, (w,h));\n",
    "\n",
    "        # Apply similarity transform on points\n",
    "        points2 = np.reshape(np.array(points1), (68,1,2));        \n",
    "        points = cv2.transform(points2, tform);\n",
    "        points = np.float32(np.reshape(points, (68, 2)));\n",
    "        \n",
    "        # Append boundary points. Will be used in Delaunay Triangulation\n",
    "        points = np.append(points, boundaryPts, axis=0)\n",
    "        \n",
    "        # Calculate location of average landmark points.\n",
    "        pointsAvg = pointsAvg + points / numImages;\n",
    "        \n",
    "        pointsNorm.append(points);\n",
    "        imagesNorm.append(img);\n",
    "        # cv2.imshow('image1', img);\n",
    "#amogh debug - trying to save the average landmarks. pc format is the one like learnopencv tutorial, and the android format is the one with  commas to be able tp save in an array.\n",
    "    # np.savetxt('txt_landmarks/androidformat.txt', pointsAvg,fmt= '%1.3f', newline=',',delimiter=',')\n",
    "    # np.savetxt('txt_landmarks/pcformat.txt', pointsAvg,fmt= '%1.3f',delimiter=' ')\n",
    "    # print pointsAvg\n",
    "\n",
    "    #redefining average points\n",
    "    pointsAvg = [];            \n",
    "    with open('C:/Users/AMOGH GUPTA/Desktop/CMU/Face Alignment/FaceAverage/txt_landmarks/pcformat.txt') as file :\n",
    "        for line in file :\n",
    "            x, y = line.split()\n",
    "            pointsAvg.append([float(x), float(y)])\n",
    "    # print pointsAvg\n",
    "    \n",
    "    rect = (0, 0, w, h);\n",
    "    dt = calculateDelaunayTriangles(rect, np.array(pointsAvg));\n",
    "\n",
    "    # Output image\n",
    "    output = np.zeros((h,w,3), np.float32());\n",
    "\n",
    "    # Warp input images to average image landmarks\n",
    "    for i in xrange(0, len(imagesNorm)) :\n",
    "        img = np.zeros((h,w,3), np.float32());\n",
    "        # Transform triangles one by one\n",
    "        for j in xrange(0, len(dt)) :\n",
    "            tin = []; \n",
    "            tout = [];\n",
    "            \n",
    "            for k in xrange(0, 3) :                \n",
    "                pIn = pointsNorm[i][dt[j][k]];\n",
    "                pIn = constrainPoint(pIn, w, h);\n",
    "                \n",
    "                pOut = pointsAvg[dt[j][k]];\n",
    "                pOut = constrainPoint(pOut, w, h);\n",
    "                \n",
    "                tin.append(pIn);\n",
    "                tout.append(pOut);\n",
    "            \n",
    "            \n",
    "            warpTriangle(imagesNorm[i], img, tin, tout);\n",
    "\n",
    "        cv2.imshow('image3', img);\n",
    "\n",
    "        # Add image intensities for averaging\n",
    "        output = output + img;\n",
    "\n",
    "    output = output / numImages;\n",
    "    mask = np.zeros((output.shape[0], output.shape[1], 3), dtype = np.float32)\n",
    "    print np.flip(points[2:7],axis=0)\n",
    "    landmarks_to_mask=np.concatenate((points[0:17],np.flip(points[17:27],axis=0)),axis=0)\n",
    "    cv2.fillConvexPoly(mask, np.int32(landmarks_to_mask), (1.0, 1.0, 1.0), 16, 0);\n",
    "    output=output*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(float('2.00000e+02'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
